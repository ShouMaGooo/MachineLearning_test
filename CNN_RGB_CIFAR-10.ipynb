{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1zMwjSwzNCAdBm07V0EJ0mS2UPZYPSDpv","authorship_tag":"ABX9TyOEnJ4y76r7KNG7OXPFrlbi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","from keras.datasets import cifar10\n","\n","\n","def prepare_data():\n","\n","\n","# データを用意する\n","\n","# returns:\n","\n","# x_train(ndarray)\n","# 訓練データ (5000,32 ,32, 3)\n","\n","# x_test(ndarray)\n","# テストデータ (1000,32 ,32, 3)\n","\n","# y_train(ndarray)\n","# 訓練データ(正解値)のone-hot化した正解ラベル(50000,)\n","\n","# y_test(ndarray)\n","# テストデータ(正解値)のone-hot化した正解ラベル(10000,)\n","\n","\n","\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","    # 訓練用とテスト用の画像データを正規化する\n","    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n","    x_train, x_test = x_train/255.0, x_test/255.0\n","\n","    # 訓練用とテスト用の正解ラベルを10クラスのOne-Hotベクトルに変換\n","    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n","\n","    return x_train, x_test, y_train, y_test"],"metadata":{"id":"jlhJq1uvYp4b","executionInfo":{"status":"ok","timestamp":1750433319619,"user_tz":-540,"elapsed":5487,"user":{"displayName":"s m","userId":"15351465247494369512"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense     # core layers\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D        # convolution layers\n","from tensorflow.keras import optimizers\n","\n","\n","def define_model():\n","    #Sequentialオブジェクトを生成\n","    model = Sequential()\n","\n","#  第1層：畳み込み層1\n","#  (バッチサイズ 32,32,3) -> (バッチサイズ 32,32,32)\n","    model.add(\n","        Conv2D(\n","              filters = 32,                   #フィルター数は32\n","              kernel_size=(3,3),              # 3x3 のフィルターを使用\n","              input_shape= x_train[0].shape,   #\n","              padding='same',                 # ゼロパディングを行う\n","              activation='relu'               # 活性化関数はReLU\n","              #kernel_initializer='he_uniform', 初期化の方法\n","              ))\n","\n"," #  第2層：畳み込み層2\n"," #  (バッチサイズ 32,32,32) -> (バッチサイズ 32,32,32)\n","    model.add(\n","        Conv2D(\n","              filters = 32,       #フィルター数は32\n","              kernel_size=(3,3),  # 3x3 のフィルターを使用\n","              activation='relu',  # 活性化関数はReLU\n","              padding='same',     # ゼロパディングを行う\n","              ))\n","\n"," #  第3層：プーリング層1\n"," #  (バッチサイズ 32,32,32) -> (バッチサイズ 16,16,32)\n","    model.add(MaxPooling2D(pool_size=(2,2)))    # 2 x 2 の範囲ごとに最大値を抜き出す (Max Pooling)\n","    model.add(Dropout(0.5))                     # ドロップアウトは50％ (ドロップアウト１)\n","\n"," #  第4層：畳み込み層3\n"," #  (バッチサイズ 16,16,32) -> (バッチサイズ 16,16,64)\n","    model.add(\n","          Conv2D(\n","                filters = 64,       #フィルター数は64\n","                kernel_size=(3,3),  # 3x3 のフィルターを使用\n","                activation='relu',  # 活性化関数はReLU\n","                padding='same',     # ゼロパディングを行う\n","                ))\n","\n"," #  第5層：畳み込み層4\n"," #  (バッチサイズ 16,16,64) -> (バッチサイズ 16,16,64)\n","    model.add(\n","          Conv2D(\n","                filters = 64,       #フィルター数は64\n","                kernel_size=(3,3),  # 3x3 のフィルターを使用\n","                activation='relu',  # 活性化関数はReLU\n","                padding='same',     # ゼロパディングを行う\n","                ))\n","\n"," #  第6層：プーリング層2\n"," #  (バッチサイズ 16,16,64) -> (バッチサイズ 8,8,64)\n","    model.add(MaxPooling2D(pool_size=(2,2)))    # 2 x 2 の範囲ごとに最大値を抜き出す (Max Pooling)\n","    model.add(Dropout(0.5))                     # ドロップアウトは50％ (ドロップアウト２)\n","\n"," # Flatten\n"," # (バッチサイズ 8,8,64) -> (バッチサイズ ,4096)\n","    model.add(Flatten())\n","\n"," #  第7層：全結合層\n"," # (バッチサイズ ,4096) -> (バッチサイズ ,512)\n","    model.add(Dense(512, activation='relu'))    # ニューロンの数は512, 活性化関数はReLU\n","\n"," # (ドロップアウト3) : ドロップアウトは50％\n","    model.add(Dropout(0.5))\n","\n"," #  第8層： 出力層\n"," # (バッチサイズ ,512) -> (バッチサイズ ,10)\n","    model.add(Dense(10, activation='softmax'))    # ニューロンの数は10, 活性化関数はソフトマックス\n","\n","    model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=optimizers.RMSprop(learning_rate=0.0001),\n","        metrics=['accuracy']\n","    )\n","\n","    return model"],"metadata":{"id":"EHisZt49z8Vs","executionInfo":{"status":"ok","timestamp":1750433319633,"user_tz":-540,"elapsed":4,"user":{"displayName":"s m","userId":"15351465247494369512"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#3. 訓練を実施する関数\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","def train(x_train, x_test, y_train, y_test):\n","\n","    #val_accuracy(検証データの精度)の改善が5エポック(学習回数)の中で見られなかったら、学習率を0.5倍する。\n","    reduce_lr = ReduceLROnPlateau(\n","        monitor='val_accuracy',   # 監視対象は検証データの精度\n","        factor=0.5,     # 学習率を減衰させる割合\n","        patience=5,     # 監視対象のエポック数\n","        verbose=1,\n","        mode='max',      # 最高値を監視する\n","        min_lr=0.00001  # 学習率の下限\n","    )\n","\n","    model = define_model()\n","    model.summary()\n","\n","    callbacks_list = [reduce_lr]\n","\n","    # データ拡張\n","    datagen = ImageDataGenerator(\n","        width_shift_range=0.1,      # 横サイズの0.1の割合でランダムに水平移動\n","        height_shift_range=0.1,     # 縦サイズの0.1の割合でランダムに垂直移動\n","        rotation_range=10,          # 10度の範囲でランダムに回転\n","        zoom_range=0.1,             # ランダムに拡大\n","        horizontal_flip=True        # 左右反転\n","    )\n","\n","\n","    # ミニバッチのサイズ\n","    batch_size = 64\n","\n","    # 学習回数\n","    epochs = 120\n","\n","    # 学習を行う\n","    history = model.fit(\n","        x_train, y_train,\n","        batch_size = batch_size,\n","        epochs=epochs,\n","        verbose=1,\n","        validation_split=0.2,\n","        shuffle=True,\n","        callbacks=callbacks_list\n","    )\n","\n","    #\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","\n","    # 損失関数を用いてlossを出力\n","    print('Test loss:', score[0])\n","\n","    # テストデータの精度を出力\n","    print('Test accuracy:', score[1])\n","\n","    return history"],"metadata":{"id":"bEYD6GwloxJz","executionInfo":{"status":"ok","timestamp":1750433319639,"user_tz":-540,"elapsed":3,"user":{"displayName":"s m","userId":"15351465247494369512"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#\n","x_train, x_test, y_train, y_test = prepare_data()\n","history = train(x_train, x_test, y_train, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cejxwjPLkl3-","executionInfo":{"status":"ok","timestamp":1750466789677,"user_tz":-540,"elapsed":3304006,"user":{"displayName":"s m","userId":"15351465247494369512"}},"outputId":"701bb9a1-0f1a-4ba2-e311-bce5cb269135"},"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,097,664\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,168,362</span> (8.27 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,168,362\u001b[0m (8.27 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,168,362</span> (8.27 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,168,362\u001b[0m (8.27 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["Epoch 1/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 396ms/step - accuracy: 0.1725 - loss: 2.2002 - val_accuracy: 0.3624 - val_loss: 1.8423 - learning_rate: 1.0000e-04\n","Epoch 2/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 386ms/step - accuracy: 0.3597 - loss: 1.7875 - val_accuracy: 0.4034 - val_loss: 1.6874 - learning_rate: 1.0000e-04\n","Epoch 3/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 382ms/step - accuracy: 0.4051 - loss: 1.6379 - val_accuracy: 0.4495 - val_loss: 1.5423 - learning_rate: 1.0000e-04\n","Epoch 4/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 392ms/step - accuracy: 0.4426 - loss: 1.5432 - val_accuracy: 0.4714 - val_loss: 1.4766 - learning_rate: 1.0000e-04\n","Epoch 5/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 394ms/step - accuracy: 0.4716 - loss: 1.4618 - val_accuracy: 0.5192 - val_loss: 1.3543 - learning_rate: 1.0000e-04\n","Epoch 6/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 383ms/step - accuracy: 0.4969 - loss: 1.4050 - val_accuracy: 0.5001 - val_loss: 1.3873 - learning_rate: 1.0000e-04\n","Epoch 7/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 378ms/step - accuracy: 0.5188 - loss: 1.3495 - val_accuracy: 0.5557 - val_loss: 1.2614 - learning_rate: 1.0000e-04\n","Epoch 8/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 385ms/step - accuracy: 0.5322 - loss: 1.2978 - val_accuracy: 0.5771 - val_loss: 1.2042 - learning_rate: 1.0000e-04\n","Epoch 9/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 385ms/step - accuracy: 0.5548 - loss: 1.2525 - val_accuracy: 0.5756 - val_loss: 1.2056 - learning_rate: 1.0000e-04\n","Epoch 10/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 385ms/step - accuracy: 0.5695 - loss: 1.2131 - val_accuracy: 0.5923 - val_loss: 1.1525 - learning_rate: 1.0000e-04\n","Epoch 11/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 385ms/step - accuracy: 0.5785 - loss: 1.1856 - val_accuracy: 0.6156 - val_loss: 1.0826 - learning_rate: 1.0000e-04\n","Epoch 12/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 392ms/step - accuracy: 0.5876 - loss: 1.1628 - val_accuracy: 0.6139 - val_loss: 1.0964 - learning_rate: 1.0000e-04\n","Epoch 13/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 391ms/step - accuracy: 0.6013 - loss: 1.1228 - val_accuracy: 0.6375 - val_loss: 1.0252 - learning_rate: 1.0000e-04\n","Epoch 14/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.6076 - loss: 1.0917 - val_accuracy: 0.6271 - val_loss: 1.0542 - learning_rate: 1.0000e-04\n","Epoch 15/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 386ms/step - accuracy: 0.6250 - loss: 1.0661 - val_accuracy: 0.6504 - val_loss: 0.9889 - learning_rate: 1.0000e-04\n","Epoch 16/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 377ms/step - accuracy: 0.6337 - loss: 1.0431 - val_accuracy: 0.6554 - val_loss: 0.9735 - learning_rate: 1.0000e-04\n","Epoch 17/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 378ms/step - accuracy: 0.6335 - loss: 1.0303 - val_accuracy: 0.6622 - val_loss: 0.9545 - learning_rate: 1.0000e-04\n","Epoch 18/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 393ms/step - accuracy: 0.6431 - loss: 1.0144 - val_accuracy: 0.6650 - val_loss: 0.9391 - learning_rate: 1.0000e-04\n","Epoch 19/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 397ms/step - accuracy: 0.6560 - loss: 0.9782 - val_accuracy: 0.6792 - val_loss: 0.9076 - learning_rate: 1.0000e-04\n","Epoch 20/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 393ms/step - accuracy: 0.6577 - loss: 0.9730 - val_accuracy: 0.6841 - val_loss: 0.8915 - learning_rate: 1.0000e-04\n","Epoch 21/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.6652 - loss: 0.9505 - val_accuracy: 0.6878 - val_loss: 0.8810 - learning_rate: 1.0000e-04\n","Epoch 22/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 389ms/step - accuracy: 0.6756 - loss: 0.9333 - val_accuracy: 0.6846 - val_loss: 0.8844 - learning_rate: 1.0000e-04\n","Epoch 23/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 401ms/step - accuracy: 0.6711 - loss: 0.9332 - val_accuracy: 0.6969 - val_loss: 0.8675 - learning_rate: 1.0000e-04\n","Epoch 24/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 403ms/step - accuracy: 0.6812 - loss: 0.9114 - val_accuracy: 0.7002 - val_loss: 0.8484 - learning_rate: 1.0000e-04\n","Epoch 25/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 393ms/step - accuracy: 0.6878 - loss: 0.8924 - val_accuracy: 0.7050 - val_loss: 0.8325 - learning_rate: 1.0000e-04\n","Epoch 26/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 390ms/step - accuracy: 0.6932 - loss: 0.8810 - val_accuracy: 0.7068 - val_loss: 0.8280 - learning_rate: 1.0000e-04\n","Epoch 27/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 387ms/step - accuracy: 0.7000 - loss: 0.8612 - val_accuracy: 0.7147 - val_loss: 0.8008 - learning_rate: 1.0000e-04\n","Epoch 28/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 435ms/step - accuracy: 0.7052 - loss: 0.8457 - val_accuracy: 0.7143 - val_loss: 0.8079 - learning_rate: 1.0000e-04\n","Epoch 29/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 424ms/step - accuracy: 0.6994 - loss: 0.8507 - val_accuracy: 0.7269 - val_loss: 0.7856 - learning_rate: 1.0000e-04\n","Epoch 30/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 424ms/step - accuracy: 0.7080 - loss: 0.8279 - val_accuracy: 0.7244 - val_loss: 0.7915 - learning_rate: 1.0000e-04\n","Epoch 31/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 421ms/step - accuracy: 0.7060 - loss: 0.8292 - val_accuracy: 0.7294 - val_loss: 0.7725 - learning_rate: 1.0000e-04\n","Epoch 32/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 428ms/step - accuracy: 0.7142 - loss: 0.8123 - val_accuracy: 0.7309 - val_loss: 0.7617 - learning_rate: 1.0000e-04\n","Epoch 33/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 425ms/step - accuracy: 0.7238 - loss: 0.7947 - val_accuracy: 0.7368 - val_loss: 0.7538 - learning_rate: 1.0000e-04\n","Epoch 34/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 416ms/step - accuracy: 0.7209 - loss: 0.7932 - val_accuracy: 0.7347 - val_loss: 0.7708 - learning_rate: 1.0000e-04\n","Epoch 35/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 391ms/step - accuracy: 0.7230 - loss: 0.7885 - val_accuracy: 0.7384 - val_loss: 0.7448 - learning_rate: 1.0000e-04\n","Epoch 36/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 383ms/step - accuracy: 0.7316 - loss: 0.7656 - val_accuracy: 0.7486 - val_loss: 0.7231 - learning_rate: 1.0000e-04\n","Epoch 37/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 424ms/step - accuracy: 0.7323 - loss: 0.7617 - val_accuracy: 0.7402 - val_loss: 0.7366 - learning_rate: 1.0000e-04\n","Epoch 38/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 416ms/step - accuracy: 0.7370 - loss: 0.7577 - val_accuracy: 0.7517 - val_loss: 0.7219 - learning_rate: 1.0000e-04\n","Epoch 39/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 418ms/step - accuracy: 0.7317 - loss: 0.7631 - val_accuracy: 0.7557 - val_loss: 0.6994 - learning_rate: 1.0000e-04\n","Epoch 40/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 429ms/step - accuracy: 0.7425 - loss: 0.7408 - val_accuracy: 0.7554 - val_loss: 0.7113 - learning_rate: 1.0000e-04\n","Epoch 41/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 428ms/step - accuracy: 0.7422 - loss: 0.7355 - val_accuracy: 0.7566 - val_loss: 0.7060 - learning_rate: 1.0000e-04\n","Epoch 42/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 430ms/step - accuracy: 0.7430 - loss: 0.7314 - val_accuracy: 0.7640 - val_loss: 0.6796 - learning_rate: 1.0000e-04\n","Epoch 43/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 428ms/step - accuracy: 0.7457 - loss: 0.7307 - val_accuracy: 0.7593 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n","Epoch 44/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 428ms/step - accuracy: 0.7495 - loss: 0.7193 - val_accuracy: 0.7614 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n","Epoch 45/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 427ms/step - accuracy: 0.7500 - loss: 0.7159 - val_accuracy: 0.7665 - val_loss: 0.6772 - learning_rate: 1.0000e-04\n","Epoch 46/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 427ms/step - accuracy: 0.7534 - loss: 0.7121 - val_accuracy: 0.7660 - val_loss: 0.6794 - learning_rate: 1.0000e-04\n","Epoch 47/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 430ms/step - accuracy: 0.7561 - loss: 0.7045 - val_accuracy: 0.7626 - val_loss: 0.6851 - learning_rate: 1.0000e-04\n","Epoch 48/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 421ms/step - accuracy: 0.7619 - loss: 0.6952 - val_accuracy: 0.7719 - val_loss: 0.6594 - learning_rate: 1.0000e-04\n","Epoch 49/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 420ms/step - accuracy: 0.7532 - loss: 0.7032 - val_accuracy: 0.7717 - val_loss: 0.6663 - learning_rate: 1.0000e-04\n","Epoch 50/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 426ms/step - accuracy: 0.7582 - loss: 0.6985 - val_accuracy: 0.7703 - val_loss: 0.6671 - learning_rate: 1.0000e-04\n","Epoch 51/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 429ms/step - accuracy: 0.7576 - loss: 0.6963 - val_accuracy: 0.7661 - val_loss: 0.6779 - learning_rate: 1.0000e-04\n","Epoch 52/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 428ms/step - accuracy: 0.7641 - loss: 0.6785 - val_accuracy: 0.7716 - val_loss: 0.6608 - learning_rate: 1.0000e-04\n","Epoch 53/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 423ms/step - accuracy: 0.7675 - loss: 0.6861 - val_accuracy: 0.7791 - val_loss: 0.6514 - learning_rate: 1.0000e-04\n","Epoch 54/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 433ms/step - accuracy: 0.7635 - loss: 0.6764 - val_accuracy: 0.7789 - val_loss: 0.6434 - learning_rate: 1.0000e-04\n","Epoch 55/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 434ms/step - accuracy: 0.7722 - loss: 0.6655 - val_accuracy: 0.7718 - val_loss: 0.6659 - learning_rate: 1.0000e-04\n","Epoch 56/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 424ms/step - accuracy: 0.7736 - loss: 0.6615 - val_accuracy: 0.7753 - val_loss: 0.6566 - learning_rate: 1.0000e-04\n","Epoch 57/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 420ms/step - accuracy: 0.7735 - loss: 0.6543 - val_accuracy: 0.7790 - val_loss: 0.6502 - learning_rate: 1.0000e-04\n","Epoch 58/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 424ms/step - accuracy: 0.7712 - loss: 0.6699 - val_accuracy: 0.7807 - val_loss: 0.6371 - learning_rate: 1.0000e-04\n","Epoch 59/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 423ms/step - accuracy: 0.7730 - loss: 0.6601 - val_accuracy: 0.7764 - val_loss: 0.6507 - learning_rate: 1.0000e-04\n","Epoch 60/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 404ms/step - accuracy: 0.7732 - loss: 0.6554 - val_accuracy: 0.7827 - val_loss: 0.6376 - learning_rate: 1.0000e-04\n","Epoch 61/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 383ms/step - accuracy: 0.7782 - loss: 0.6520 - val_accuracy: 0.7776 - val_loss: 0.6474 - learning_rate: 1.0000e-04\n","Epoch 62/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 396ms/step - accuracy: 0.7748 - loss: 0.6585 - val_accuracy: 0.7816 - val_loss: 0.6331 - learning_rate: 1.0000e-04\n","Epoch 63/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 412ms/step - accuracy: 0.7779 - loss: 0.6479 - val_accuracy: 0.7792 - val_loss: 0.6398 - learning_rate: 1.0000e-04\n","Epoch 64/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 423ms/step - accuracy: 0.7769 - loss: 0.6460 - val_accuracy: 0.7821 - val_loss: 0.6377 - learning_rate: 1.0000e-04\n","Epoch 65/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 421ms/step - accuracy: 0.7800 - loss: 0.6416 - val_accuracy: 0.7866 - val_loss: 0.6370 - learning_rate: 1.0000e-04\n","Epoch 66/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 409ms/step - accuracy: 0.7802 - loss: 0.6470 - val_accuracy: 0.7882 - val_loss: 0.6236 - learning_rate: 1.0000e-04\n","Epoch 67/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 418ms/step - accuracy: 0.7825 - loss: 0.6409 - val_accuracy: 0.7845 - val_loss: 0.6419 - learning_rate: 1.0000e-04\n","Epoch 68/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 411ms/step - accuracy: 0.7835 - loss: 0.6415 - val_accuracy: 0.7906 - val_loss: 0.6209 - learning_rate: 1.0000e-04\n","Epoch 69/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 409ms/step - accuracy: 0.7821 - loss: 0.6366 - val_accuracy: 0.7851 - val_loss: 0.6303 - learning_rate: 1.0000e-04\n","Epoch 70/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 419ms/step - accuracy: 0.7848 - loss: 0.6409 - val_accuracy: 0.7854 - val_loss: 0.6326 - learning_rate: 1.0000e-04\n","Epoch 71/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 408ms/step - accuracy: 0.7878 - loss: 0.6180 - val_accuracy: 0.7894 - val_loss: 0.6292 - learning_rate: 1.0000e-04\n","Epoch 72/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 422ms/step - accuracy: 0.7872 - loss: 0.6334 - val_accuracy: 0.7908 - val_loss: 0.6194 - learning_rate: 1.0000e-04\n","Epoch 73/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 437ms/step - accuracy: 0.7850 - loss: 0.6273 - val_accuracy: 0.7896 - val_loss: 0.6336 - learning_rate: 1.0000e-04\n","Epoch 74/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 429ms/step - accuracy: 0.7855 - loss: 0.6289 - val_accuracy: 0.7878 - val_loss: 0.6287 - learning_rate: 1.0000e-04\n","Epoch 75/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 427ms/step - accuracy: 0.7865 - loss: 0.6248 - val_accuracy: 0.7885 - val_loss: 0.6309 - learning_rate: 1.0000e-04\n","Epoch 76/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 420ms/step - accuracy: 0.7851 - loss: 0.6283 - val_accuracy: 0.7895 - val_loss: 0.6320 - learning_rate: 1.0000e-04\n","Epoch 77/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 385ms/step - accuracy: 0.7887 - loss: 0.6101 - val_accuracy: 0.7966 - val_loss: 0.6023 - learning_rate: 1.0000e-04\n","Epoch 78/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 387ms/step - accuracy: 0.7923 - loss: 0.6166 - val_accuracy: 0.7983 - val_loss: 0.6082 - learning_rate: 1.0000e-04\n","Epoch 79/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 386ms/step - accuracy: 0.7915 - loss: 0.6114 - val_accuracy: 0.8007 - val_loss: 0.5973 - learning_rate: 1.0000e-04\n","Epoch 80/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 408ms/step - accuracy: 0.7824 - loss: 0.6340 - val_accuracy: 0.7866 - val_loss: 0.6397 - learning_rate: 1.0000e-04\n","Epoch 81/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 422ms/step - accuracy: 0.7900 - loss: 0.6197 - val_accuracy: 0.7953 - val_loss: 0.6129 - learning_rate: 1.0000e-04\n","Epoch 82/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 412ms/step - accuracy: 0.7928 - loss: 0.6161 - val_accuracy: 0.7940 - val_loss: 0.6086 - learning_rate: 1.0000e-04\n","Epoch 83/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 412ms/step - accuracy: 0.7920 - loss: 0.6175 - val_accuracy: 0.7908 - val_loss: 0.6223 - learning_rate: 1.0000e-04\n","Epoch 84/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7917 - loss: 0.6086\n","Epoch 84: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 413ms/step - accuracy: 0.7917 - loss: 0.6086 - val_accuracy: 0.7947 - val_loss: 0.6096 - learning_rate: 1.0000e-04\n","Epoch 85/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 424ms/step - accuracy: 0.8021 - loss: 0.5815 - val_accuracy: 0.7989 - val_loss: 0.6002 - learning_rate: 5.0000e-05\n","Epoch 86/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 424ms/step - accuracy: 0.8057 - loss: 0.5750 - val_accuracy: 0.7956 - val_loss: 0.5994 - learning_rate: 5.0000e-05\n","Epoch 87/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 411ms/step - accuracy: 0.8078 - loss: 0.5731 - val_accuracy: 0.7993 - val_loss: 0.5986 - learning_rate: 5.0000e-05\n","Epoch 88/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 425ms/step - accuracy: 0.8064 - loss: 0.5783 - val_accuracy: 0.7996 - val_loss: 0.5956 - learning_rate: 5.0000e-05\n","Epoch 89/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8030 - loss: 0.5836\n","Epoch 89: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 423ms/step - accuracy: 0.8030 - loss: 0.5836 - val_accuracy: 0.7971 - val_loss: 0.6022 - learning_rate: 5.0000e-05\n","Epoch 90/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 411ms/step - accuracy: 0.8093 - loss: 0.5731 - val_accuracy: 0.7999 - val_loss: 0.5921 - learning_rate: 2.5000e-05\n","Epoch 91/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 416ms/step - accuracy: 0.8094 - loss: 0.5693 - val_accuracy: 0.8004 - val_loss: 0.5878 - learning_rate: 2.5000e-05\n","Epoch 92/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 423ms/step - accuracy: 0.8070 - loss: 0.5712 - val_accuracy: 0.7994 - val_loss: 0.5908 - learning_rate: 2.5000e-05\n","Epoch 93/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 430ms/step - accuracy: 0.8077 - loss: 0.5634 - val_accuracy: 0.8011 - val_loss: 0.5890 - learning_rate: 2.5000e-05\n","Epoch 94/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 418ms/step - accuracy: 0.8023 - loss: 0.5731 - val_accuracy: 0.8004 - val_loss: 0.5908 - learning_rate: 2.5000e-05\n","Epoch 95/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 422ms/step - accuracy: 0.8120 - loss: 0.5639 - val_accuracy: 0.8013 - val_loss: 0.5885 - learning_rate: 2.5000e-05\n","Epoch 96/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 420ms/step - accuracy: 0.8096 - loss: 0.5728 - val_accuracy: 0.8027 - val_loss: 0.5887 - learning_rate: 2.5000e-05\n","Epoch 97/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 426ms/step - accuracy: 0.8027 - loss: 0.5765 - val_accuracy: 0.8027 - val_loss: 0.5906 - learning_rate: 2.5000e-05\n","Epoch 98/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 416ms/step - accuracy: 0.8076 - loss: 0.5619 - val_accuracy: 0.8023 - val_loss: 0.5866 - learning_rate: 2.5000e-05\n","Epoch 99/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 428ms/step - accuracy: 0.8099 - loss: 0.5583 - val_accuracy: 0.8048 - val_loss: 0.5853 - learning_rate: 2.5000e-05\n","Epoch 100/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 416ms/step - accuracy: 0.8114 - loss: 0.5611 - val_accuracy: 0.8026 - val_loss: 0.5903 - learning_rate: 2.5000e-05\n","Epoch 101/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 418ms/step - accuracy: 0.8089 - loss: 0.5620 - val_accuracy: 0.8017 - val_loss: 0.5864 - learning_rate: 2.5000e-05\n","Epoch 102/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 416ms/step - accuracy: 0.8164 - loss: 0.5556 - val_accuracy: 0.8051 - val_loss: 0.5828 - learning_rate: 2.5000e-05\n","Epoch 103/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 420ms/step - accuracy: 0.8141 - loss: 0.5530 - val_accuracy: 0.8052 - val_loss: 0.5850 - learning_rate: 2.5000e-05\n","Epoch 104/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 408ms/step - accuracy: 0.8082 - loss: 0.5580 - val_accuracy: 0.8039 - val_loss: 0.5886 - learning_rate: 2.5000e-05\n","Epoch 105/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 421ms/step - accuracy: 0.8084 - loss: 0.5664 - val_accuracy: 0.8044 - val_loss: 0.5814 - learning_rate: 2.5000e-05\n","Epoch 106/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 419ms/step - accuracy: 0.8143 - loss: 0.5562 - val_accuracy: 0.8031 - val_loss: 0.5910 - learning_rate: 2.5000e-05\n","Epoch 107/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8127 - loss: 0.5678\n","Epoch 107: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 410ms/step - accuracy: 0.8127 - loss: 0.5678 - val_accuracy: 0.8030 - val_loss: 0.5869 - learning_rate: 2.5000e-05\n","Epoch 108/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 418ms/step - accuracy: 0.8113 - loss: 0.5527 - val_accuracy: 0.8034 - val_loss: 0.5848 - learning_rate: 1.2500e-05\n","Epoch 109/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 404ms/step - accuracy: 0.8106 - loss: 0.5660 - val_accuracy: 0.8036 - val_loss: 0.5826 - learning_rate: 1.2500e-05\n","Epoch 110/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 406ms/step - accuracy: 0.8118 - loss: 0.5609 - val_accuracy: 0.8034 - val_loss: 0.5859 - learning_rate: 1.2500e-05\n","Epoch 111/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 417ms/step - accuracy: 0.8141 - loss: 0.5559 - val_accuracy: 0.8024 - val_loss: 0.5907 - learning_rate: 1.2500e-05\n","Epoch 112/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 415ms/step - accuracy: 0.8106 - loss: 0.5586 - val_accuracy: 0.8062 - val_loss: 0.5801 - learning_rate: 1.2500e-05\n","Epoch 113/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 415ms/step - accuracy: 0.8152 - loss: 0.5562 - val_accuracy: 0.8035 - val_loss: 0.5826 - learning_rate: 1.2500e-05\n","Epoch 114/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 417ms/step - accuracy: 0.8142 - loss: 0.5605 - val_accuracy: 0.8043 - val_loss: 0.5838 - learning_rate: 1.2500e-05\n","Epoch 115/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 414ms/step - accuracy: 0.8088 - loss: 0.5577 - val_accuracy: 0.8024 - val_loss: 0.5892 - learning_rate: 1.2500e-05\n","Epoch 116/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 403ms/step - accuracy: 0.8094 - loss: 0.5601 - val_accuracy: 0.8032 - val_loss: 0.5864 - learning_rate: 1.2500e-05\n","Epoch 117/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8125 - loss: 0.5583\n","Epoch 117: ReduceLROnPlateau reducing learning rate to 1e-05.\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 416ms/step - accuracy: 0.8125 - loss: 0.5583 - val_accuracy: 0.8029 - val_loss: 0.5857 - learning_rate: 1.2500e-05\n","Epoch 118/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 415ms/step - accuracy: 0.8151 - loss: 0.5422 - val_accuracy: 0.8041 - val_loss: 0.5840 - learning_rate: 1.0000e-05\n","Epoch 119/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 404ms/step - accuracy: 0.8134 - loss: 0.5552 - val_accuracy: 0.8056 - val_loss: 0.5788 - learning_rate: 1.0000e-05\n","Epoch 120/120\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 405ms/step - accuracy: 0.8129 - loss: 0.5502 - val_accuracy: 0.8043 - val_loss: 0.5809 - learning_rate: 1.0000e-05\n","Test loss: 0.6019534468650818\n","Test accuracy: 0.7964000105857849\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DDfCvyCzSe0G","executionInfo":{"status":"ok","timestamp":1750466789689,"user_tz":-540,"elapsed":2,"user":{"displayName":"s m","userId":"15351465247494369512"}}},"execution_count":4,"outputs":[]}]}